---
title: 游牧计算
date: 2025-03-11T14:59:03.303Z
---

在使用 LLM 的时候很容易陷入两个极端之一：完全信任服务提供商（无论是 OpenAI/Deepseek 这样的官方服务，还是像 SiliconFlow/OpenRouter 这样的推理提供商），或者是完全自己部署。前者很方便，外包了复杂度，但是也意味着模型不受自己控制；后者很自由，但前提是得有足够多的钱买卡。

但其实全托管-自托管是一段连续的光谱，游牧计算（Nomadic Compute）则是其中一个有趣的中间点。这个概念似乎一位外国博主 Xe Iaso 创造的，指的是像游牧民族那样，带着自己的数据在不同的云服务基础设施提供商之间漫游，逐水草而居（实际上是价格最低的 GPU）。这样的行为方式之所以能成立，是因为计算（Nvidia GPU）和存储（假设使用某种对象存储服务，例如 S3 或者各种 S3-兼容服务）都是云供应商中立，可以互换的。只要你在需要时在价格最低的云上启动实例，并在不用的时候完全关闭，就能享受到相对低的价格和更自由的选择，并且避免供应商锁定。

如果这听起来很有趣，你应该继续阅读这篇演讲记录。

https://xeiaso.net/talks/2025/ai-chatbot-friends/


或者看看已有的帮你自动跨云服务商找最低价 GPU 并完成计算的开源项目

https://github.com/skypilot-org/skypilot/