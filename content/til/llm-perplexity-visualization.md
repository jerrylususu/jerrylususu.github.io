---
title: 用 LLM 计算可视化文字的信息增量
date: 2025-03-09T15:39:03.518Z
---

读 LLM 推理相关的资料时，想到：在 LLM 前向推理的过程中，会计算从输入开头到当前 token 的所有 token 的 logit，最后采样的时候只用了最后一个 token 的 logit；是否可以构建一个工具，用户输入一段文本，让LLM计算每个token上出现用户输入token的概率，并且加点可视化（概率大：说明这个接续很常见，没什么信息增量；概率小：说明这个接续不太常见，可能有点意思），来得到一个展示文本信息增量的工具？

搜了搜，发现果然已经有人做过了，用的是 GPT-2 （虽然老了一些，但是足够小，可以直接跑在浏览器里），效果也很棒。或许可以考虑下用现代的 SLM（Small Language Model）更新下？

https://perplexity.vercel.app/