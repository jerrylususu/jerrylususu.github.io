<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>理论 on Nekonull&#39;s Garden</title>
    <link>https://nekonull.me/tags/%E7%90%86%E8%AE%BA/</link>
    <description>Recent content in 理论 on Nekonull&#39;s Garden</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 10 May 2022 17:04:00 +0300</lastBuildDate><atom:link href="https://nekonull.me/tags/%E7%90%86%E8%AE%BA/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>(译) 复杂系统如何失效</title>
      <link>https://nekonull.me/posts/how-complex-system-fail-cn/</link>
      <pubDate>Tue, 10 May 2022 17:04:00 +0300</pubDate>
      
      <guid>https://nekonull.me/posts/how-complex-system-fail-cn/</guid>
      <description>&lt;h1 id=&#34;复杂系统如何失效&#34;&gt;复杂系统如何失效&lt;/h1&gt;
&lt;p&gt;原文链接：&lt;a href=&#34;https://how.complexsystems.fail/&#34;&gt;How Complex Systems Fail&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;译者注：在阅读 Slack Engineering Team 发布的 &lt;a href=&#34;https://slack.engineering/slacks-incident-on-2-22-22/&#34;&gt;2022/2/22 事故报告&lt;/a&gt;时，注意到了这篇文章。作者描述了系统的复杂性为维护人员带来的挑战，并澄清了一些常见误解。个人认为这篇文章很有价值，但可惜暂无中文翻译，于是便自己动手了。本译文在 DeepL 机翻的基础上润色调整而成，错误在所难免，如有发现还请指正。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;1-复杂系统本质上是危险的系统&#34;&gt;1. 复杂系统本质上是危险的系统&lt;/h2&gt;
&lt;p&gt;所有有趣的系统（如交通、医疗、发电），因其本身的性质，都具有固有的、不可避免的危险性。危险暴露的频率有时可以改变，但系统涉及的流程，依然具有内在的、不可减少的危险性。正是这些危险的存在，推动了防御措施的产生。危险和防御的存在也成为了这些系统的特征。&lt;/p&gt;
&lt;h2 id=&#34;2-对系统失效复杂系统有大量成功的防御措施&#34;&gt;2. 对系统失效，复杂系统有大量成功的防御措施&lt;/h2&gt;
&lt;p&gt;随着时间推移，系统失效可能造成的严重后果，推动了多层防御措施的构建。这些防御措施不仅包括明显的技术部分（如备用系统、设备的「安全」特性）和人力部分（如培训、知识），也包括各种组织的、机构的、监管的防御措施（如政策和程序、认证、工作规则、团队建设）。这些措施如同一系列盾牌，通常会将系统运行导向远离事故的方向。&lt;/p&gt;
&lt;h2 id=&#34;3-灾难发生需要多重故障--单点故障是不够的&#34;&gt;3. 灾难发生需要多重故障 —— 单点故障是不够的&lt;/h2&gt;
&lt;p&gt;一系列的防御措施是有效的。系统的运作通常是成功的。但当多个看似无害的小故障同时发生时，系统性事故才有机可乘，并最终导致显性的灾难性失效。尽管这些小故障中的每一个都是灾难的必要条件，但只有它们组合起来，才足以引发灾难。换句话说，系统可能失效（但没有失效）的时机，远比公开表现出来的系统失效多得多。大多数故障轨迹一开始就被系统中的安全组件阻挡了，而到达系统运作层面的故障轨迹，通常被一线工作者阻挡。&lt;/p&gt;
&lt;h2 id=&#34;4-复杂系统包含不断变化的潜在故障&#34;&gt;4. 复杂系统包含不断变化的潜在故障&lt;/h2&gt;
&lt;p&gt;这类系统的复杂性，使得它们不可能在没有多个缺陷存在的情况下运行。（系统中总是存在缺陷。）因为这些缺陷单独不足以导致失效，所以运行期间它们通常被视为次要因素。消除所有的潜在故障（是不可能的），主要受到经济成本的限制。另一原因是，很难在事故发生前，发现潜在故障引发事故的方式。此外，因为技术、组织和消除故障的努力的变化，这些潜在故障本身也在不断变化。&lt;/p&gt;
&lt;h2 id=&#34;5-复杂系统带病运行&#34;&gt;5. 复杂系统带病运行&lt;/h2&gt;
&lt;p&gt;基于前一点，一个必然的推论是：复杂系统像损坏的系统一样运行。尽管存在许多缺陷，系统之所以能继续工作，不仅是因为其本身包含了许多冗余，也是因为工作人员可以让它运行。事故发生后的回顾，几乎总是会注意到，事故发生前，系统就已经有一系列「原事故（proto-accident）」的历史。这些「原事故」差点就会引发灾难。一种论调认为，这些已经退化（降级）的运行条件，在事故发生前就应该被意识到，但这一论调是建立在对系统工作状况的天真认识上的。系统的运作是动态的，这一过程中系统的组成部分（组织、人、技术）不断失效又被替换。&lt;/p&gt;
&lt;h2 id=&#34;6-灾难总在拐角处&#34;&gt;6. 灾难总在拐角处&lt;/h2&gt;
&lt;p&gt;复杂系统具有灾难性失效的可能性。灾难可能在任何时间、任何地点发生，而一线工作者几乎总是在物理上和时间上接近这些潜在的故障。潜在的灾难性结果是复杂系统的标志之一。（从复杂系统中）消除这种灾难性失效是不可能的。由于系统本身的性质，失效的可能性始终存在。&lt;/p&gt;
&lt;h2 id=&#34;7-事后分析的根因根本上是错的&#34;&gt;7. 事后分析的「根因」根本上是错的&lt;/h2&gt;
&lt;p&gt;因为显性的失效需要多重故障，所以并不存在一个独立的事故「原因」。多种因素导致了事故的发生，其中每个因素单独并不足以引发事故，只有它们联合起来才足以造成事故。正是这些因素联系在一起，才创造了事故所需的环境。因此，不可能将某个事故的「根因（root-cause）」分离出来。事故评估中对「根因」的论证，并非出于对失效本质的技术性理解，而是出于将结果归咎于特定的、局部的力量的社会文化需要。[1]&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[1] 人类学的田野调查为「原因」这一概念的社会构建提供了最清晰的证明。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;8-事后回顾中对人为表现的评估存在偏见&#34;&gt;8. 事后回顾中对人为表现的评估存在偏见&lt;/h2&gt;
&lt;p&gt;对结果的了解使人认为，对一线人员而言，导致失效的事件比实际情况显得更突出。这意味着对人为表现的事后分析是不准确的。对结果的了解阻碍了事后观察者重现事故前一线人员视角的能力，显得一线人员似乎「应该知道」这些因素「不可避免地」会引发事故。[2] 后见之明偏见仍然是事故调查的主要障碍，尤其是在涉及到人类专家的表现时。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[2] 这不是医学判断或技术判断的特点，而是人类对过去事件及其原因认知上的特点。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;9-人类操作者有双重角色生产者和失效防御者&#34;&gt;9. 人类操作者有双重角色：生产者和失效防御者&lt;/h2&gt;
&lt;p&gt;一线人员操作系统运转，不仅为了生产所需的产品，也为了防止事故发生。系统运行的动态性，即平衡为满足需求而生产和避免潜在故障，是不可避免的。外人很少承认这一角色的双重性。在没有事故发生时，生产的角色被强调。在事故发生后，失效防御者的角色被强调。无论在哪种情况下，外人的视角都误解了操作者对两种角色的同时参与。&lt;/p&gt;
&lt;h2 id=&#34;10-所有一线人员的行为都是赌博&#34;&gt;10. 所有一线人员的行为都是赌博&lt;/h2&gt;
&lt;p&gt;事故发生后，显式的失效看似不可避免，而一线人员的行为则被视为愚蠢的错误，或对迫近事故的故意漠视。但所有一线人员的行为，实际上都是赌博，或者说，是面对不确定结果的行动。不确定性的程度可能时刻变化。一线人员的行为是赌博，这一点在事故后看起来很明显；一般来说，事后分析都认为这些赌博是糟糕的。但反过来说，成功结局也是赌博的结果，但这一点并没有得到广泛重视。&lt;/p&gt;
&lt;h2 id=&#34;11-棘手之处的行为消除了模糊性&#34;&gt;11. 棘手之处的行为消除了模糊性&lt;/h2&gt;
&lt;p&gt;组织对生产目标、资源的高效利用、经济和运营成本以及可接受的事故风险是模糊的。这一模糊性往往又是故意为之的。但一线人员在系统棘手之处的行动消除了模糊性。事故发生后，一线人员的行为可能被认为是「错误」或「违规」，但这些评价严重被后见之明偏见影响，而忽略了其他的驱动力，特别是生产压力。&lt;/p&gt;
&lt;h2 id=&#34;12-人类操作者是复杂系统的改造者&#34;&gt;12. 人类操作者是复杂系统的改造者&lt;/h2&gt;
&lt;p&gt;一线工作者和一线管理人员积极调整系统，以最大化生产和最小化事故。这些调整往往时刻发生。其中一些调整包括（1）重组系统，以减少脆弱部分在故障下的暴露。（2）将关键资源集中到预期的高需求区域。（3）提供从预期和意外故障中撤退或恢复的途径。（4）建立对系统性能变化的早期检测手段，以允许优雅地削减生产，或是其他增加系统弹性的手段。&lt;/p&gt;
&lt;h2 id=&#34;13-复杂系统中人的专业知识是不断变化的&#34;&gt;13. 复杂系统中，人的专业知识是不断变化的&lt;/h2&gt;
&lt;p&gt;复杂系统的运行和管理需要大量的专业知识。这些专业知识随技术变化而变化，但也因为需要替换离开的专家而变化。在任何情况下，对技能和专业知识的训练和完善，都是系统本身功能的一部分。因此，在任何时候，一个特定的复杂系统将包含专业知识程度不同的从业者和受训者。和专业知识相关的关键问题来自于（1）需要将稀缺的专业知识作为资源，用于最困难或最苛刻的生产需求；（2）需要发展专业知识，以供未来使用。&lt;/p&gt;
&lt;h2 id=&#34;14-变化引入了新的故障形式&#34;&gt;14. 变化引入了新的故障形式&lt;/h2&gt;
&lt;p&gt;可靠系统中的低显性事故率，可能会鼓励变化，特别是对新技术的应用，以减少后果轻微但出现频率高的故障。这些变化可能实际上为新的、出现频率低但后果严重的故障创造了机会。当新技术被用于消除已经被理解透彻的系统故障，或是为了获得更高性能、更精确结果时，它们往往会引入新的、导致大规模灾难性失效的途径。并不少见的是，这些新的、罕见的灾难，甚至比这些新技术试图消除的故障影响更大。在事故发生前，这些新的故障模式难以被发现；大部分注意力被集中到这些修改带来的假定存在的有益特征上。因为这些新的、后果严重的事故发生的几率很低，在事故发生前可能引入了多个系统修改，使得人们很难看到技术对故障的贡献。&lt;/p&gt;
&lt;h2 id=&#34;15-对原因的观点限制了对未来事件的防御措施的有效性&#34;&gt;15. 对「原因」的观点限制了对未来事件的防御措施的有效性&lt;/h2&gt;
&lt;p&gt;事后对「人为错误」的补救措施，通常以阻碍可能「造成」事故的行动为前提。这些链条末端的措施对减少未来发生事故的可能性没有什么作用。实际上，因为潜在故障的模式不断变化，发生相同事故的可能性本身就已经非常低了。事后的补救措施，不仅没有增加安全性，反倒增加了系统的耦合度和复杂性。这不仅增加了潜在故障的数量，也使得检测和组织事故轨迹变得更加困难。&lt;/p&gt;
&lt;h2 id=&#34;16-安全是系统的特性而非其组成部分的特性&#34;&gt;16. 安全是系统的特性，而非其组成部分的特性&lt;/h2&gt;
&lt;p&gt;安全是系统的一种涌现（emergent）属性；它不存在于一个组织或系统的某个人、设备和部门中。安全不能被购买和制造；它不是一个独立于系统之外其他组成部分的特征。这意味着，安全不能像原料或原材料那样被操纵。任何系统中的安全状态都是动态的；持续的系统变化保证了（系统中的）危险和对危险的管理都是不断变化的。&lt;/p&gt;
&lt;h2 id=&#34;17-人不断创造安全&#34;&gt;17. 人不断创造安全&lt;/h2&gt;
&lt;p&gt;无故障运行是人们通过各种活动，努力将系统保持在可容忍的工作状况边界内的结果。这些活动大部分情况下是正常操作的一部分，表面上看起来也很直接。但因为系统的运作从来都不是没有故障的，人类操作者对不断变化的运行条件的适应，实际上每时每刻都在创造安全。这些适应往往只是从现有的对策中选出一个已经反复排练过的程序；但有时，这些适应是对新方法的全新组合，甚至重新创造。&lt;/p&gt;
&lt;h2 id=&#34;18-无故障操作需要有故障经验&#34;&gt;18. 无故障操作需要有故障经验&lt;/h2&gt;
&lt;p&gt;识别危险并成功操纵系统，使其留在可容忍的工作状况边界内（的能力），需要与失败有亲密的接触。在操作人员能辨别「包络边缘」的系统中，可能会产生更健壮的系统效能。（「包络边缘」）是系统的性能开始退化，变得难以预测，或无法轻易恢复之处。在内在危险的系统中，操作者应能面对并理解危险，并将系统导向理想的性能状态。提升安全性，取决于为操作者提供对危险的准确看法，也取决于让操作者准确了解他们的操作将如何影响系统性能，是朝向还是离开包络边缘。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>